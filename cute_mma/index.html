<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>MMA 操作详解 - CUTLASS Notes</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "MMA \u64cd\u4f5c\u8be6\u89e3";
        var mkdocs_page_input_path = "cute_mma.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> CUTLASS Notes
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">CuTe</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../cute_core/">Cute 核心概念</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../cute_layout/">Layout 布局系统</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../cute_tensor/">Tensor 张量操作</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Copy 操作</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../cute_copy/">Copy 操作详解</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../cute_tma_copy/">TMA Copy 操作</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" >MMA 操作</a>
    <ul class="current">
                <li class="toctree-l2 current"><a class="reference internal current" href="#">MMA 操作详解</a>
    <ul class="current">
    <li class="toctree-l3"><a class="reference internal" href="#mma">MMA 基本概念</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#cute-mma">CuTe MMA 抽象层次</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#1-operation">1. Operation 结构体</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#2-mma_traits">2. MMA_Traits 特性结构体</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#3-mma_atom">3. MMA_Atom 原子操作</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#4-tiledmma">4. TiledMMA 平铺操作</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#algorithm-gemm">Algorithm GEMM 接口</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#mma_atom">MMA_Atom</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#mma_1">MMA 操作示例</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#mma_thrcall-cutegemm">mma_thr.call() 与 cute::gemm() 的区别</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#mma_thrcall">mma_thr.call() 的特点：</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#cutegemm">cute::gemm() 的特点：</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#_1">使用建议：</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#gmma-descriptor-swizzle">GMMA Descriptor 与 Swizzle 信息</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#accumulator-fragment">累加片段 (Accumulator Fragment)</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#copy">与 Copy 操作的协同</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#_2">不同架构的支持</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#volta-sm70">Volta (SM70)</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#turing-sm75">Turing (SM75)</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#ampere-sm80">Ampere (SM80)</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#hopper-sm90">Hopper (SM90)</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#_3">高级特性</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#_4">可扩展性</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#_5">灵活的布局支持</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#_6">类型安全</a>
    </li>
        </ul>
    </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../cute_wgmma_sm90/">GMMA(SM90)</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../cute_examples/">实际应用示例</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">CUTLASS Notes</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">CuTe</li>
          <li class="breadcrumb-item">MMA 操作</li>
      <li class="breadcrumb-item active">MMA 操作详解</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="cute-mma-matrix-multiply-accumulate">CuTe MMA (Matrix Multiply-Accumulate) 操作</h1>
<p>MMA (Matrix Multiply-Accumulate) 是 CuTe 中用于执行矩阵乘加运算的核心组件。在深度学习和科学计算中，MMA 操作是最关键的计算之一。</p>
<h2 id="mma">MMA 基本概念</h2>
<p>MMA 操作执行以下计算：</p>
<pre><code class="language-cpp">D = A * B + C
</code></pre>
<p>其中 A、B 是输入矩阵，C 是累加矩阵，D 是输出矩阵。</p>
<p>在 CuTe 中，MMA 操作被高度抽象化，允许开发者：</p>
<ul>
<li>使用不同精度的数据类型</li>
<li>利用专门的硬件指令（如 Tensor Cores）</li>
<li>适应不同的内存布局</li>
<li>与线程协作进行大规模计算</li>
</ul>
<h2 id="cute-mma">CuTe MMA 抽象层次</h2>
<p>CuTe 对 MMA 操作进行了多层抽象，从底层硬件指令到高级接口：</p>
<h3 id="1-operation">1. Operation 结构体</h3>
<p>Operation 结构体封装了特定的 PTX 指令。它定义了指令所需的寄存器类型和实际的 fma 函数实现。</p>
<p>设计原因：</p>
<ul>
<li>将底层硬件指令封装在统一接口下，隐藏硬件差异</li>
<li>明确定义寄存器使用模式，便于编译器优化</li>
<li>提供类型安全的接口，防止寄存器类型错误</li>
</ul>
<p>例如，<code>SM70_8x8x4_F32F16F16F32_NT</code> 定义了 Volta 架构上的一个 MMA 操作：</p>
<pre><code class="language-cpp">struct SM70_8x8x4_F32F16F16F32_NT
{
  // 定义 D 矩阵使用的寄存器类型和数量
  // 8个float寄存器用于存储8x8矩阵的输出结果
  using DRegisters = float[8];

  // 定义 A 矩阵使用的寄存器类型和数量
  // 2个uint32_t寄存器，每个包含2个F16值（共4个F16值）
  using ARegisters = uint32_t[2];

  // 定义 B 矩阵使用的寄存器类型和数量
  // 与A矩阵相同，2个uint32_t寄存器
  using BRegisters = uint32_t[2];

  // 定义 C 矩阵使用的寄存器类型和数量
  // 8个float寄存器用于存储8x8矩阵的输入和累加结果
  using CRegisters = float[8];

  // FMA操作的静态函数实现
  // 通过内联汇编调用实际的PTX指令
  CUTE_HOST_DEVICE static void
  fma(float      &amp; d0, float      &amp; d1, float      &amp; d2, float      &amp; d3,
      float      &amp; d4, float      &amp; d5, float      &amp; d6, float      &amp; d7,
      uint32_t const&amp; a0, uint32_t const&amp; a1,
      uint32_t const&amp; b0, uint32_t const&amp; b1,
      float  const&amp; c0, float  const&amp; c1, float  const&amp; c2, float  const&amp; c3,
      float  const&amp; c4, float  const&amp; c5, float  const&amp; c6, float  const&amp; c7)
  {
    // 实际的 PTX 指令调用
    // 执行 8x8x4 的矩阵乘法累加操作
    // .m8n8k4 表示操作的尺寸：M=8, N=8, K=4
    // .row.col 表示 A 矩阵是行主序，B 矩阵是列主序
    // .f32.f16.f16.f32 表示数据类型：D(F32), A(F16), B(F16), C(F32)
    asm volatile(
      &quot;mma.sync.aligned.m8n8k4.row.col.f32.f16.f16.f32&quot;
      &quot;{%0, %1, %2, %3, %4, %5, %6, %7},&quot;
      &quot;{%8, %9},&quot;
      &quot;{%10, %11},&quot;
      &quot;{%12, %13, %14, %15, %16, %17, %18, %19};&quot;
      : &quot;=f&quot;(d0), &quot;=f&quot;(d1), &quot;=f&quot;(d2), &quot;=f&quot;(d3), 
        &quot;=f&quot;(d4), &quot;=f&quot;(d5), &quot;=f&quot;(d6), &quot;=f&quot;(d7)
      :  &quot;r&quot;(a0),  &quot;r&quot;(a1),
         &quot;r&quot;(b0),  &quot;r&quot;(b1),
        &quot;f&quot;(c0), &quot;f&quot;(c1), &quot;f&quot;(c2), &quot;f&quot;(c3), 
        &quot;f&quot;(c4), &quot;f&quot;(c5), &quot;f&quot;(c6), &quot;f&quot;(c7));
  }
};
</code></pre>
<h3 id="2-mma_traits">2. MMA_Traits 特性结构体</h3>
<p>MMA_Traits 为每个 Operation 提供元信息，包括：</p>
<ul>
<li>ValTypeD, ValTypeA, ValTypeB, ValTypeC: 逻辑数据类型</li>
<li>Shape_MNK: MMA 操作的逻辑形状(MxNxK)</li>
<li>ThrID: MMA 操作中的线程映射</li>
<li>ALayout, BLayout, CLayout: 线程和值到坐标空间的映射布局</li>
</ul>
<p>设计原因：</p>
<ul>
<li>分离硬件指令实现和逻辑信息描述</li>
<li>提供编译时元信息，支持模板特化</li>
<li>描述线程和数据的布局关系，便于内存访问优化</li>
</ul>
<pre><code class="language-cpp">template &lt;&gt;
struct MMA_Traits&lt;SM70_8x8x4_F32F16F16F32_NT&gt;
{
  // 定义逻辑数据类型
  using ValTypeD = float;   // 输出矩阵 D 的类型
  using ValTypeA = half_t;  // 输入矩阵 A 的类型
  using ValTypeB = half_t;  // 输入矩阵 B 的类型
  using ValTypeC = float;   // 输入/输出矩阵 C 的类型

  // 定义 MMA 操作的逻辑形状：M=8, N=8, K=4
  using Shape_MNK = Shape&lt;_8,_8,_4&gt;;

  // 定义线程ID映射布局
  // 4x2布局，步幅为1和16
  // 表示8个线程组成的quadpair结构
  using ThrID = Layout&lt;Shape &lt;_4, _2&gt;, Stride&lt;_1,_16&gt;&gt;;

  // 定义 A 矩阵的线程-值布局
  // Shape &lt;Shape &lt;_4,_2&gt;,_4&gt; 表示 4x2 的线程布局和 4 个值
  // Stride&lt;Stride&lt;_8,_4&gt;,_1&gt; 定义了内存访问的步幅模式
  using ALayout = Layout&lt;Shape &lt;Shape &lt;_4,_2&gt;,_4&gt;, Stride&lt;Stride&lt;_8,_4&gt;,_1&gt;&gt;;

  // 定义 B 矩阵的线程-值布局
  // 与 A 矩阵相同，因为它们有相似的访问模式
  using BLayout = Layout&lt;Shape &lt;Shape &lt;_4,_2&gt;,_4&gt;, Stride&lt;Stride&lt;_8,_4&gt;,_1&gt;&gt;;

  // 定义 C 矩阵的线程-值布局
  // 更复杂的三维布局，精确描述了8个线程如何访问8个值
  using CLayout = Layout&lt;Shape &lt;Shape &lt;_2, _2,_2&gt;, Shape &lt;_2,_2, _2&gt;&gt;,
                         Stride&lt;Stride&lt;_1,_16,_4&gt;, Stride&lt;_8,_2,_32&gt;&gt;&gt;;
};
</code></pre>
<h3 id="3-mma_atom">3. MMA_Atom 原子操作</h3>
<p>MMA_Atom 将 Operation 和 MMA_Traits 结合起来，提供统一接口：</p>
<p>设计原因：</p>
<ul>
<li>统一封装Operation和Traits，提供一致的API</li>
<li>支持模板特化，可以针对不同操作进行优化</li>
<li>提供make_fragment方法，便于创建适合的张量片段</li>
<li>实现call接口，简化MMA操作的调用</li>
</ul>
<pre><code class="language-cpp">// 主模板，通过MMA_Traits特化来实现具体功能
template &lt;class MMAOperation&gt;
struct MMA_Atom&lt;MMAOperation&gt; : MMA_Atom&lt;MMA_Traits&lt;MMAOperation&gt;&gt;
{};

// 特化版本，实现具体功能
template &lt;class MMAOperation, class... Args&gt;
struct MMA_Atom&lt;MMA_Traits&lt;MMAOperation, Args...&gt;&gt;
  : MMA_Traits&lt;MMAOperation, Args...&gt;
{
  // 从Traits继承类型定义
  using ValTypeD = typename Traits::ValTypeD;
  using ValTypeA = typename Traits::ValTypeA;
  using ValTypeB = typename Traits::ValTypeB;
  using ValTypeC = typename Traits::ValTypeC;

  using Shape_MNK  = typename Traits::Shape_MNK;
  using ThrID      = typename Traits::ThrID;
  using LayoutC_TV = typename Traits::CLayout;
  using LayoutA_TV = typename Traits::ALayout;
  using LayoutB_TV = typename Traits::BLayout;

  // 主要的调用接口
  // 接受四个张量参数：D(输出), A(输入), B(输入), C(输入/输出)
  template &lt;class TD, class DLayout,
            class TA, class ALayout,
            class TB, class BLayout,
            class TC, class CLayout&gt;
  CUTE_HOST_DEVICE constexpr
  void
  call(Tensor&lt;TD, DLayout&gt;      &amp; D,
       Tensor&lt;TA, ALayout&gt; const&amp; A,
       Tensor&lt;TB, BLayout&gt; const&amp; B,
       Tensor&lt;TC, CLayout&gt; const&amp; C) const
  {
    // 静态断言确保张量是一维的（寄存器级操作）
    static_assert(DLayout::rank == 1, &quot;Expected rank-1 D tensor&quot;);
    static_assert(ALayout::rank == 1, &quot;Expected rank-1 A tensor&quot;);
    static_assert(BLayout::rank == 1, &quot;Expected rank-1 B tensor&quot;);
    static_assert(CLayout::rank == 1, &quot;Expected rank-1 C tensor&quot;);

    // 调用底层的mma_unpack函数执行实际操作
    return mma_unpack(static_cast&lt;Traits const&amp;&gt;(*this), D, A, B, C);
  }

  // 三个参数的重载版本，复用C作为输出
  template &lt;class TA, class ALayout,
            class TB, class BLayout,
            class TC, class CLayout&gt;
  CUTE_HOST_DEVICE constexpr
  void
  call(Tensor&lt;TA, ALayout&gt; const&amp; A,
       Tensor&lt;TB, BLayout&gt; const&amp; B,
       Tensor&lt;TC, CLayout&gt;      &amp; C) const
  {
    // 调用四参数版本，将C同时作为输入和输出
    return call(C, A, B, C);
  }
};
</code></pre>
<h3 id="4-tiledmma">4. TiledMMA 平铺操作</h3>
<p>TiledMMA 允许将多个 MMA_Atom 组合成更大的操作，支持多线程协作：</p>
<p>设计原因：</p>
<ul>
<li>支持更大规模的矩阵运算，超越单个MMA指令的能力</li>
<li>实现线程级别的并行化，提高硬件利用率</li>
<li>提供灵活的平铺策略，适应不同的内存布局需求</li>
<li>通过组合多个Atom，构建更复杂的计算模式</li>
</ul>
<pre><code class="language-cpp">// TiledMMA模板定义
// MMA_Atom: 基础的MMA操作原子
// AtomLayoutMNK: 在MNK维度上Atom的布局
// PermutationMNK: 应用于每个MNK模式的排列
template &lt;class MMA_Atom,
          class AtomLayoutMNK,
          class PermutationMNK = Tile&lt;Underscore,Underscore,Underscore&gt;&gt;
struct TiledMMA : MMA_Atom
{
  // 从MMA_Atom继承相关类型
  using Atom           = MMA_Atom;
  using AtomShape_MNK  = typename MMA_Atom::Shape_MNK;
  using AtomThrID      = typename MMA_Atom::ThrID;
  using AtomLayoutC_TV = typename MMA_Atom::LayoutC_TV;
  using AtomLayoutA_TV = typename MMA_Atom::LayoutA_TV;
  using AtomLayoutB_TV = typename MMA_Atom::LayoutB_TV;

  // 线程布局，通过将AtomThrID与AtomLayoutMNK进行tiled_product得到
  using ThrLayoutVMNK = decltype(tiled_product(AtomThrID{}, AtomLayoutMNK{}));
  ThrLayoutVMNK thr_layout_vmnk_;

  // 构造函数
  CUTE_HOST_DEVICE constexpr
  TiledMMA(MMA_Atom const&amp; mma_atom = {}, AtomLayoutMNK const&amp; thr_layout_mnk = {})
    : MMA_Atom(mma_atom),
      thr_layout_vmnk_(tiled_product(AtomThrID{}, thr_layout_mnk)) {}

  // 获取线程布局
  CUTE_HOST_DEVICE constexpr auto
  get_thr_layout_vmnk() const {
    return thr_layout_vmnk_;
  }

  // 根据线程索引获取切片
  template &lt;class ThrIdx&gt;
  CUTE_HOST_DEVICE constexpr
  auto
  get_slice(ThrIdx const&amp; thr_idx) const
  {
    // 将线程索引转换为VMNK坐标
    auto thr_vmnk = thr_layout_vmnk_.get_flat_coord(thr_idx);
    // 返回ThrMMA对象，用于特定线程的操作
    return ThrMMA&lt;TiledMMA, decltype(thr_vmnk)&gt;{*this, thr_vmnk};
  }
};

// ThrMMA为特定线程提供操作接口
template &lt;class TiledMMA, class ThrVMNK&gt;
struct ThrMMA : TiledMMA
{
  ThrVMNK thr_vmnk_;

  // 分区C矩阵，为当前线程准备数据
  template &lt;class CTensor&gt;
  CUTE_HOST_DEVICE constexpr
  auto
  partition_C(CTensor&amp;&amp; ctensor) const
  {
    // 创建张量并应用thrfrg_C布局变换
    auto thr_tensor = make_tensor(static_cast&lt;CTensor&amp;&amp;&gt;(ctensor).data(), 
                                  this-&gt;thrfrg_C(ctensor.layout()));

    // 构造线程坐标并获取当前线程的数据切片
    auto thr_vmn = make_coord(get&lt;0&gt;(thr_vmnk_), 
                              make_coord(get&lt;1&gt;(thr_vmnk_), get&lt;2&gt;(thr_vmnk_)));
    return thr_tensor(thr_vmn, make_coord(_, repeat&lt;rank&lt;1,1&gt;(thr_tensor)&gt;(_)));
  }

  // 类似地实现 partition_A 和 partition_B
};
</code></pre>
<h2 id="algorithm-gemm">Algorithm GEMM 接口</h2>
<p>CuTe 提供了统一的 GEMM 接口，可以处理不同层次的矩阵乘法操作：</p>
<p>设计原因：</p>
<ul>
<li>提供统一的接口，隐藏底层实现复杂性</li>
<li>支持多种数据布局和内存类型</li>
<li>根据张量维度和内存类型自动分发到合适的实现</li>
<li>实现寄存器级和共享内存级操作的统一调用</li>
</ul>
<pre><code class="language-cpp">// 基本 GEMM 接口，使用通用FMA操作
template &lt;class TD, class DLayout,
          class TA, class ALayout,
          class TB, class BLayout,
          class TC, class CLayout&gt;
CUTE_HOST_DEVICE
void
gemm(Tensor&lt;TD, DLayout&gt;      &amp; D,
     Tensor&lt;TA, ALayout&gt; const&amp; A,
     Tensor&lt;TB, BLayout&gt; const&amp; B,
     Tensor&lt;TC, CLayout&gt; const&amp; C)
{
  // 根据张量的数据类型创建合适的MMA操作
  using MMA = MMA_Atom&lt;UniversalFMA&lt;typename Tensor&lt;TD,DLayout&gt;::value_type,
                                    typename Tensor&lt;TA,ALayout&gt;::value_type,
                                    typename Tensor&lt;TB,BLayout&gt;::value_type,
                                    typename Tensor&lt;TC,CLayout&gt;::value_type&gt;&gt;;

  // 调用具体的GEMM实现
  return gemm(MMA{}, D, A, B, C);
}

// 使用特定 MMA_Atom 的 GEMM 接口
template &lt;class MMA,
          class TD, class DLayout,
          class TA, class ALayout,
          class TB, class BLayout,
          class TC, class CLayout&gt;
CUTE_HOST_DEVICE
void
gemm(MMA_Atom&lt;MMA&gt;       const&amp; mma,
     Tensor&lt;TD, DLayout&gt;      &amp; D,
     Tensor&lt;TA, ALayout&gt; const&amp; A,
     Tensor&lt;TB, BLayout&gt; const&amp; B,
     Tensor&lt;TC, CLayout&gt; const&amp; C)
{
  // 根据张量的维度和内存类型进行分发
  // Dispatch [1]: (V) x (V) =&gt; (V) - 元素级乘法，直接调用MMA原子操作
  // Dispatch [2]: (M) x (N) =&gt; (M,N) - 外积，转换为矩阵乘法
  // Dispatch [3]: (M,K) x (N,K) =&gt; (M,N) - 矩阵乘法，添加向量维度
  // Dispatch [4]: (V,M) x (V,N) =&gt; (V,M,N) - 批量外积，按元素进行寄存器优化
  // Dispatch [5]: (V,M,K) x (V,N,K) =&gt; (V,M,N) - 批量矩阵乘法，按K维度循环处理

  // 这种分发机制使得GEMM接口可以处理从简单元素操作到复杂批量矩阵运算的各种情况
}
</code></pre>
<h2 id="mma_atom">MMA_Atom</h2>
<p>MMA_Atom 是 CuTe 中 MMA 操作的基本构建块。它封装了：</p>
<ul>
<li>实际的 MMA 指令（如 HMMA、WMMA 等）</li>
<li>输入和输出的布局信息</li>
<li>MMA 操作的约束条件</li>
</ul>
<p>MMA_Atom 可以针对不同的硬件架构和数据类型进行优化。</p>
<h2 id="mma_1">MMA 操作示例</h2>
<p>一个典型的 MMA 操作可能如下所示：</p>
<pre><code class="language-cpp">// 定义输入张量 A、B 和累加张量 C
auto A_tensor = make_tensor(A_ptr, A_layout);
auto B_tensor = make_tensor(B_ptr, B_layout);
auto C_tensor = make_tensor(C_ptr, C_layout);

// 创建 MMA 操作对象
auto mma_atom = MMA_Atom&lt;SM70_8x8x4_F32F16F16F32_NT&gt;{};

// 获取 MMA 操作的参与者
auto mma_thr = mma_atom.get_thread_slice(thread_idx);

// 创建累加片段
auto accum_fragment = make_fragment_like(C_tensor);
clear(accum_fragment);

// 执行 MMA 操作
mma_thr.call(A_tensor, B_tensor, accum_fragment);
</code></pre>
<h2 id="mma_thrcall-cutegemm">mma_thr.call() 与 cute::gemm() 的区别</h2>
<p>虽然可以直接使用 <code>mma_thr.call()</code> 执行 MMA 操作，但 CuTe 仍然提供了 <code>cute::gemm()</code> 接口，这是因为两者有不同的使用场景和抽象层次：</p>
<h3 id="mma_thrcall">mma_thr.call() 的特点：</h3>
<ul>
<li><strong>低级接口</strong>：直接操作寄存器级别的张量片段</li>
<li><strong>精确控制</strong>：需要手动管理张量的分区和布局</li>
<li><strong>硬件相关</strong>：需要明确指定使用的 MMA 操作类型</li>
<li><strong>适合场景</strong>：需要精细控制计算过程的高性能场景</li>
</ul>
<h3 id="cutegemm">cute::gemm() 的特点：</h3>
<ul>
<li><strong>高级接口</strong>：提供统一的 GEMM 接口，自动处理底层细节</li>
<li><strong>自动分发</strong>：根据张量的维度和内存类型自动选择合适的实现</li>
<li><strong>类型推导</strong>：可以根据输入张量的类型自动推导合适的 MMA 操作</li>
<li><strong>灵活适配</strong>：可以处理从简单元素操作到复杂批量矩阵运算的各种情况</li>
<li><strong>适合场景</strong>：通用的矩阵乘法计算，简化开发流程</li>
</ul>
<h3 id="_1">使用建议：</h3>
<pre><code class="language-cpp">// 当需要精细控制时，使用 mma_thr.call()
auto mma_atom = MMA_Atom&lt;SM70_8x8x4_F32F16F16F32_NT&gt;{};
auto mma_thr = mma_atom.get_thread_slice(thread_idx);
mma_thr.call(A_frag, B_frag, C_frag);

// 当需要通用接口时，使用 cute::gemm()
cute::gemm(D_tensor, A_tensor, B_tensor, C_tensor);
</code></pre>
<p>总的来说，<code>mma_thr.call()</code> 提供了更底层、更精确的控制，而 <code>cute::gemm()</code> 提供了更高级、更通用的接口。开发者可以根据具体需求选择合适的接口。</p>
<h2 id="gmma-descriptor-swizzle">GMMA Descriptor 与 Swizzle 信息</h2>
<p>对于 Hopper (SM90) 架构中的 GMMA 操作，请参考专门的文档：<a href="../cute_wgmma_sm90/">CuTe WGmma SM90</a></p>
<h2 id="accumulator-fragment">累加片段 (Accumulator Fragment)</h2>
<p>在 MMA 操作中，累加片段是非常重要的概念。它代表了累加器寄存器中的数据块。CuTe 提供了专门的类型和操作来处理累加片段：</p>
<pre><code class="language-cpp">// 创建累加片段
auto accum_fragment = make_fragment_like(C_tensor);

// 初始化累加片段
clear(accum_fragment);

// 执行多次 MMA 操作累加结果
mma_thr.call(A_tensor, B_tensor, accum_fragment, accum_fragment);
</code></pre>
<h2 id="copy">与 Copy 操作的协同</h2>
<p>在实际应用中，MMA 操作通常与 Copy 操作协同工作：</p>
<ul>
<li>使用 Copy 操作将数据从全局内存加载到共享内存或寄存器</li>
<li>使用 MMA 操作执行计算</li>
<li>使用 Copy 操作将结果从寄存器写回到全局内存</li>
</ul>
<p>这种协同工作模式充分利用了 GPU 的内存层次结构和计算能力。</p>
<h2 id="_2">不同架构的支持</h2>
<p>CuTe 支持多种 NVIDIA GPU 架构的 MMA 指令：</p>
<h3 id="volta-sm70">Volta (SM70)</h3>
<ul>
<li>使用 HMMA 指令</li>
<li>8个线程的 quadpair 协作完成 8x8x4 的矩阵乘法</li>
</ul>
<h3 id="turing-sm75">Turing (SM75)</h3>
<ul>
<li>增强的 HMMA 指令支持</li>
</ul>
<h3 id="ampere-sm80">Ampere (SM80)</h3>
<ul>
<li>更多的 MMA 指令变体</li>
<li>对稀疏矩阵乘法的支持</li>
</ul>
<h3 id="hopper-sm90">Hopper (SM90)</h3>
<ul>
<li>引入了新一代的 GMMA (Group MMA) 指令</li>
<li>支持更大的矩阵操作 (如 64x128x16)</li>
<li>warpgroup 级别的协作 (128个线程)</li>
</ul>
<h2 id="_3">高级特性</h2>
<p>CuTe 的 MMA 操作具有以下高级特性：</p>
<h3 id="_4">可扩展性</h3>
<p>通过 TiledMMA，可以轻松地扩展基本的 MMA 操作以适应更大的矩阵计算需求。</p>
<h3 id="_5">灵活的布局支持</h3>
<p>CuTe 的 Layout 系统使得可以灵活地处理不同的数据布局，包括行主序、列主序以及自定义布局。</p>
<h3 id="_6">类型安全</h3>
<p>通过模板和类型系统，确保在编译时就能发现类型不匹配的错误。</p>
<p>这些抽象使得开发者可以编写高效且可维护的 CUDA 代码，同时充分利用现代 GPU 的计算能力。</p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../cute_tma_copy/" class="btn btn-neutral float-left" title="TMA Copy 操作"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../cute_wgmma_sm90/" class="btn btn-neutral float-right" title="GMMA(SM90)">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../cute_tma_copy/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../cute_wgmma_sm90/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
