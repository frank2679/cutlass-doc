<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>实际应用示例 - CUTLASS Notes</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "\u5b9e\u9645\u5e94\u7528\u793a\u4f8b";
        var mkdocs_page_input_path = "cute_examples.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> CUTLASS Notes
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">CuTe</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../cute_core/">Cute 核心概念</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../cute_layout/">Layout 布局系统</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../cute_tensor/">Tensor 张量操作</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Copy 操作</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../cute_copy/">Copy 操作详解</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../cute_tma_copy/">TMA Copy 操作</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >MMA 操作</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../cute_mma/">MMA 操作详解</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../cute_wgmma_sm90/">GMMA(SM90)</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="#">实际应用示例</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#copy">基本 Copy 操作示例</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#_1">矩阵转置示例</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#tiledcopy">使用 TiledCopy 的示例</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#mma">MMA 操作示例</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#tma-copy">TMA Copy 示例</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#gemm">复合示例：GEMM 实现</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#_2">性能优化技巧</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#1">1. 内存对齐</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#2">2. 合理的块大小选择</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#3">3. 向量化内存访问</a>
    </li>
        </ul>
    </li>
    </ul>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">CUTLASS Notes</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">CuTe</li>
      <li class="breadcrumb-item active">实际应用示例</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="cute">CuTe 实际应用示例</h1>
<p>通过具体的示例来展示如何使用 CuTe 构建高性能的 CUDA 程序。</p>
<h2 id="copy">基本 Copy 操作示例</h2>
<p>以下示例展示了如何使用 CuTe 执行基本的 Copy 操作。</p>
<pre><code class="language-cpp">#include &lt;cute/tensor.hpp&gt;

using namespace cute;

__global__ void copy_example() {
  // 定义数据指针
  float *src_ptr = /* 源数据指针 */;
  float *dst_ptr = /* 目标数据指针 */;

  // 创建 Layout
  auto layout = make_layout(make_shape(32, 32), GenRowMajor{});

  // 创建 Tensor
  auto src_tensor = make_tensor(make_gmem_ptr(src_ptr), layout);
  auto dst_tensor = make_tensor(make_gmem_ptr(dst_ptr), layout);

  // 执行 Copy 操作
  copy(src_tensor, dst_tensor);
}
</code></pre>
<h2 id="_1">矩阵转置示例</h2>
<p>这个示例展示了如何使用 CuTe 实现高效的矩阵转置。</p>
<pre><code class="language-cpp">#include &lt;cute/tensor.hpp&gt;

using namespace cute;

__global__ void matrix_transpose() {
  // 定义矩阵维度
  constexpr int M = 64;
  constexpr int N = 64;

  // 获取数据指针
  float *src_ptr = /* 源矩阵指针 */;
  float *dst_ptr = /* 目标矩阵指针 */;

  // 创建源矩阵 Tensor (行主序)
  auto src_layout = make_layout(make_shape(M, N), GenRowMajor{});
  auto src_tensor = make_tensor(make_gmem_ptr(src_ptr), src_layout);

  // 创建目标矩阵 Tensor (列主序，实现转置效果)
  auto dst_layout = make_layout(make_shape(M, N), GenColMajor{});
  auto dst_tensor = make_tensor(make_gmem_ptr(dst_ptr), dst_layout);

  // 执行 Copy 操作，实现转置
  copy(src_tensor, dst_tensor);
}
</code></pre>
<h2 id="tiledcopy">使用 TiledCopy 的示例</h2>
<p>这个示例展示了如何使用 TiledCopy 实现高效的块状复制。</p>
<pre><code class="language-cpp">#include &lt;cute/tensor.hpp&gt;

using namespace cute;

__global__ void tiled_copy_example() {
  // 定义块大小
  constexpr int BLK_M = 32;
  constexpr int BLK_N = 32;

  // 获取数据指针
  float *src_ptr = /* 源数据指针 */;
  float *dst_ptr = /* 目标数据指针 */;

  // 创建 Layout
  auto layout = make_layout(make_shape(BLK_M, BLK_N), GenRowMajor{});

  // 创建 Tensor
  auto src_tensor = make_tensor(make_gmem_ptr(src_ptr), layout);
  auto dst_tensor = make_tensor(make_gmem_ptr(dst_ptr), layout);

  // 创建 TiledCopy
  auto tiled_copy = make_tiled_copy(Copy_Atom&lt;UniversalCopy&lt;float&gt;, float&gt;{},
                                   make_shape(BLK_M, BLK_N),
                                   make_shape(4, 8));  // 4x8 线程块

  // 获取线程切片
  auto thr_copy = tiled_copy.get_thread_slice(threadIdx.x);

  // 分区张量
  auto src_frag = thr_copy.partition_S(src_tensor);
  auto dst_frag = thr_copy.partition_D(dst_tensor);

  // 执行复制
  copy(src_frag, dst_frag);
}
</code></pre>
<h2 id="mma">MMA 操作示例</h2>
<p>这个示例展示了如何使用 CuTe 执行矩阵乘加操作。</p>
<pre><code class="language-cpp">#include &lt;cute/tensor.hpp&gt;

using namespace cute;

__global__ void mma_example() {
  // 定义矩阵维度
  constexpr int M = 16;
  constexpr int N = 16;
  constexpr int K = 8;

  // 获取数据指针
  half_t *A_ptr = /* A 矩阵指针 */;
  half_t *B_ptr = /* B 矩阵指针 */;
  float  *C_ptr = /* C 矩阵指针 */;

  // 创建张量 Layout
  auto A_layout = make_layout(make_shape(M, K), GenRowMajor{});
  auto B_layout = make_layout(make_shape(N, K), GenColMajor{});
  auto C_layout = make_layout(make_shape(M, N), GenRowMajor{});

  // 创建张量
  auto A_tensor = make_tensor(make_gmem_ptr(A_ptr), A_layout);
  auto B_tensor = make_tensor(make_gmem_ptr(B_ptr), B_layout);
  auto C_tensor = make_tensor(make_gmem_ptr(C_ptr), C_layout);

  // 创建 MMA 操作
  auto mma_atom = MMA_Atom&lt;SM70_8x8x4_F32F16F16F32_NT&gt;{};

  // 获取线程切片
  auto mma_thr = mma_atom.get_thread_slice(threadIdx.x);

  // 分区张量
  auto A_frag = mma_thr.partition_A(A_tensor);
  auto B_frag = mma_thr.partition_B(B_tensor);
  auto C_frag = mma_thr.partition_C(C_tensor);

  // 创建累加片段
  auto acc_frag = make_fragment_like(C_frag);
  clear(acc_frag);

  // 执行 MMA 操作
  mma_thr.mma(A_frag, B_frag, acc_frag, acc_frag);

  // 将结果写回
  copy(acc_frag, C_frag);
}
</code></pre>
<h2 id="tma-copy">TMA Copy 示例</h2>
<p>这个示例展示了如何在 Hopper 架构上使用 TMA 进行高效的内存复制。</p>
<pre><code class="language-cpp">#include &lt;cute/tensor.hpp&gt;

using namespace cute;

#if defined(CUTE_ARCH_TMA_SM90_ENABLED)
__global__ void tma_copy_example() {
  // 定义矩阵维度
  constexpr int M = 512;
  constexpr int N = 512;

  // 获取数据指针
  float *gmem_ptr = /* 全局内存指针 */;
  extern __shared__ float smem[];

  // 创建全局内存张量
  auto gmem_tensor = make_tensor(make_gmem_ptr(gmem_ptr),
                                make_shape(M, N),
                                GenRowMajor{});

  // 创建共享内存 Layout
  auto smem_layout = tile_to_shape(GMMA::Layout_MN_SW128_Atom&lt;float&gt;{},
                                  make_shape(64, 64));

  // 创建共享内存张量
  auto smem_tensor = make_tensor(make_smem_ptr&lt;float&gt;(smem), smem_layout);

  // 创建 TMA Copy 对象
  auto tma_load = make_tma_copy(SM90_TMA_LOAD{},
                               gmem_tensor,
                               smem_layout);

  // 获取 TMA 张量
  auto tma_tensor = tma_load.get_tma_tensor(make_shape(M, N));

  // 分块处理
  auto tma_gmem = local_tile(tma_tensor, make_shape(64, 64), make_coord(blockIdx.x, blockIdx.y));

  // 获取线程切片
  auto thr_x = tma_load.get_slice(threadIdx.x);

  // 分区张量
  auto tma_gmem_x = thr_x.partition_S(tma_gmem);
  auto tma_smem_x = thr_x.partition_D(smem_tensor);

  // 同步对象
  uint64_t bar;
  auto mbar = make_mbarrier(bar);

  // 执行 TMA 加载
  copy(tma_load.with(mbar), tma_gmem_x, tma_smem_x);

  // 等待完成
  tma_load.wait(mbar);
}
#endif
</code></pre>
<h2 id="gemm">复合示例：GEMM 实现</h2>
<p>这个示例展示了一个完整的 GEMM (General Matrix Multiply) 实现。</p>
<pre><code class="language-cpp">#include &lt;cute/tensor.hpp&gt;

using namespace cute;

template &lt;class TiledMMA, class TiledCopyA, class TiledCopyB&gt;
__global__ void gemm_example(TiledMMA  tiled_mma,
                            TiledCopyA tiled_copy_a,
                            TiledCopyB tiled_copy_b) {
  // 获取共享内存指针
  extern __shared__ float smem[];

  // 分配共享内存给 A 和 B
  float *smem_a = smem;
  float *smem_b = smem + sizeof(float) * 64 * 16;

  // 创建共享内存张量
  auto smem_a_tensor = make_tensor(make_smem_ptr&lt;float&gt;(smem_a),
                                  make_layout(make_shape(64, 16), GenRowMajor{}));
  auto smem_b_tensor = make_tensor(make_smem_ptr&lt;float&gt;(smem_b),
                                  make_layout(make_shape(64, 16), GenRowMajor{}));

  // 获取数据指针
  float *A_ptr = /* A 矩阵指针 */;
  float *B_ptr = /* B 矩阵指针 */;
  float *C_ptr = /* C 矩阵指针 */;

  // 创建全局内存张量
  auto A_tensor = make_tensor(make_gmem_ptr(A_ptr),
                             make_layout(make_shape(64, 64), GenRowMajor{}));
  auto B_tensor = make_tensor(make_gmem_ptr(B_ptr),
                             make_layout(make_shape(64, 64), GenColMajor{}));
  auto C_tensor = make_tensor(make_gmem_ptr(C_ptr),
                             make_layout(make_shape(64, 64), GenRowMajor{}));

  // 获取 MMA 切片
  auto mma_thr = tiled_mma.get_thread_slice(threadIdx.x);

  // 分区累加张量
  auto C_frag = mma_thr.partition_C(C_tensor);
  auto acc_frag = make_fragment_like(C_frag);
  clear(acc_frag);

  // 主计算循环
  for (int k = 0; k &lt; 64; k += 16) {
    // 分区源张量
    auto A_frag = tiled_copy_a.partition_S(A_tensor(_, make_coord(k, k+16)));
    auto B_frag = tiled_copy_b.partition_S(B_tensor(_, make_coord(k, k+16)));

    // 分区目标张量
    auto smem_a_frag = tiled_copy_a.partition_D(smem_a_tensor);
    auto smem_b_frag = tiled_copy_b.partition_D(smem_b_tensor);

    // 复制数据到共享内存
    copy(tiled_copy_a, A_frag, smem_a_frag);
    copy(tiled_copy_b, B_frag, smem_b_frag);

    // 同步
    __syncthreads();

    // 分区共享内存张量用于计算
    auto smem_a_mma = mma_thr.partition_A(smem_a_tensor);
    auto smem_b_mma = mma_thr.partition_B(smem_b_tensor);

    // 执行 MMA 操作
    gemm(tiled_mma, smem_a_mma, smem_b_mma, acc_frag);

    // 同步
    __syncthreads();
  }

  // 将结果写回
  copy(acc_frag, C_frag);
}
</code></pre>
<h2 id="_2">性能优化技巧</h2>
<p>在实际应用中，需要注意以下性能优化技巧：</p>
<h4 id="1">1. 内存对齐</h4>
<pre><code class="language-cpp">// 确保数据对齐以获得最佳性能
alignas(128) float data[1024];  // 128 字节对齐
</code></pre>
<h4 id="2">2. 合理的块大小选择</h4>
<pre><code class="language-cpp">// 根据硬件特性选择合适的块大小
constexpr int TILE_M = 128;  // 适应 GPU 的 warp 大小
constexpr int TILE_N = 64;   // 平衡寄存器使用和并行度
constexpr int TILE_K = 16;   // 适应 MMA 指令的要求
</code></pre>
<h4 id="3">3. 向量化内存访问</h4>
<pre><code class="language-cpp">// 使用合适的 Layout 实现向量化访问
auto vectorized_layout = make_layout(make_shape(32, 8),
                                    make_stride(8, 1));  // 实现 8 元素向量化
</code></pre>
<p>这些示例展示了 CuTe 在实际应用中的强大功能。通过合理使用 CuTe 的各种组件，可以构建出高性能、可维护的 CUDA 程序。</p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../cute_wgmma_sm90/" class="btn btn-neutral float-left" title="GMMA(SM90)"><span class="icon icon-circle-arrow-left"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../cute_wgmma_sm90/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
